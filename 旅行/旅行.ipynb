{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ChromeDriverの実際のパスを指定\n",
    "chrome_driver_path = '/usr/local/bin/chromedriver'  # 実際のパスに変更\n",
    "\n",
    "# ブラウザオプションの設定\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# ドライバーの起動\n",
    "driver = webdriver.Chrome(service=Service(chrome_driver_path),\n",
    "                          options=chrome_options\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import sqlite3\n",
    "\n",
    "# Selenium WebDriver設定\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "url = \"https://www.jalan.net/jalan/doc/etc/onsenranking/onsenranking_index.html\"\n",
    "driver.get(url)\n",
    "\n",
    "# ページ読み込みを待つ\n",
    "time.sleep(3)\n",
    "\n",
    "# ページソースを取得\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# データ格納用リスト\n",
    "onsen_data = []\n",
    "\n",
    "# 1〜3位を処理\n",
    "top_items = soup.find_all(\"div\", class_=\"areaItem\", limit=3)\n",
    "for rank, item in enumerate(top_items, start=1):\n",
    "    try:\n",
    "        # 順位は`alt`属性から取得\n",
    "        rank_tag = item.find(\"span\", class_=\"rank\")\n",
    "        if rank_tag and rank_tag.find(\"img\"):\n",
    "            rank = rank_tag.find(\"img\")[\"alt\"].replace(\"No.\", \"\").strip()\n",
    "        else:\n",
    "            rank = str(rank)  # 順位が数字ならそのまま使用\n",
    "\n",
    "        # エリア名と温泉名を取得\n",
    "        area = item.find(\"span\", class_=\"areaName\").get_text(strip=True)\n",
    "        onsen_name = item.find(\"h3\").contents[-1].strip()  # `<h3>`内の最後のテキスト\n",
    "\n",
    "        onsen_data.append({\"順位\": int(rank), \"エリア名\": area, \"温泉名\": onsen_name})\n",
    "    except Exception as e:\n",
    "        print(f\"1〜3位エラー: {e}\")\n",
    "\n",
    "# 4位以降を処理\n",
    "ranking_items = soup.find_all(\"div\", class_=[\"areaItem\", \"areaItem3col\"])\n",
    "for item in ranking_items:\n",
    "    try:\n",
    "        # 順位を取得\n",
    "        rank_tag = item.find(\"span\", class_=[\"rank\", \"rank_g\"])\n",
    "        if rank_tag:\n",
    "            rank = rank_tag.get_text(strip=True).replace(\"位\", \"\").strip()\n",
    "            if not rank.isdigit():  # 順位が数字でない場合はスキップ\n",
    "                continue\n",
    "            rank = int(rank)\n",
    "\n",
    "        area = item.find(\"span\", class_=\"areaName\").get_text(strip=True)\n",
    "        onsen_name = item.find(\"span\", class_=\"areaName\").find_next_sibling(string=True).strip()\n",
    "\n",
    "        # 重複チェック\n",
    "        if not any(d[\"エリア名\"] == area and d[\"温泉名\"] == onsen_name for d in onsen_data):\n",
    "            onsen_data.append({\"順位\": rank, \"エリア名\": area, \"温泉名\": onsen_name})\n",
    "    except Exception as e:\n",
    "        print(f\"4位以降エラー: {e}\")\n",
    "\n",
    "# WebDriverを終了\n",
    "driver.quit()\n",
    "\n",
    "# DataFrameに変換\n",
    "df = pd.DataFrame(onsen_data)\n",
    "\n",
    "# 順位でソート\n",
    "df = df.sort_values(\"順位\").reset_index(drop=True)\n",
    "\n",
    "# 結果を表示\n",
    "print(df)\n",
    "\n",
    "# 必要に応じてCSVに保存\n",
    "df.to_csv(\"onsen_ranking_fixed.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# SQLiteデータベースに接続（なければ作成されます）\n",
    "conn = sqlite3.connect('onsen_data.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "# データベースにテーブルを作成\n",
    "c.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS onsen (\n",
    "        順位 INTEGER PRIMARY KEY,\n",
    "        エリア名 TEXT,\n",
    "        温泉名 TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# DataFrameのデータをデータベースに挿入\n",
    "for index, row in df.iterrows():\n",
    "    c.execute('''\n",
    "        INSERT OR REPLACE INTO onsen (順位, エリア名, 温泉名) VALUES (?, ?, ?)\n",
    "    ''', (row['順位'], row['エリア名'], row['温泉名']))\n",
    "\n",
    "# データベースへの保存確認\n",
    "conn.commit()\n",
    "\n",
    "# データベース接続を閉じる\n",
    "conn.close()\n",
    "\n",
    "print(\"データベースに保存完了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Selenium WebDriver設定\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# タイムアウト設定を長くする\n",
    "driver.set_page_load_timeout(180)\n",
    "\n",
    "# データ取得をリトライする関数\n",
    "def fetch_data_with_retry(url, retries=3, delay=5):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            return driver.page_source\n",
    "        except Exception as e:\n",
    "            if attempt < retries - 1:\n",
    "                print(f\"再試行 {attempt + 1}/{retries} 回目... エラー: {e}\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(f\"最終試行でもエラーが発生しました: {e}\")\n",
    "                raise e\n",
    "\n",
    "# URLを指定してデータを取得\n",
    "url = \"https://www.siken.net/j_ranking?stat=pdensity_top\"\n",
    "html = fetch_data_with_retry(url)\n",
    "\n",
    "# ページ読み込み後、BeautifulSoupで解析\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# データ格納用リスト\n",
    "population_density_data = []\n",
    "\n",
    "# テーブルから人口密度を取得\n",
    "table = soup.find(\"table\")\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "for row in rows[1:]:  # ヘッダーをスキップ\n",
    "    try:\n",
    "        cells = row.find_all(\"td\")\n",
    "        if len(cells) >= 3:\n",
    "            rank = cells[0].get_text(strip=True)\n",
    "            prefecture = cells[1].get_text(strip=True)\n",
    "            population_density = cells[2].get_text(strip=True)\n",
    "\n",
    "            # 結果をリストに格納\n",
    "            population_density_data.append({\n",
    "                \"順位\": int(rank.replace(\"位\", \"\")),\n",
    "                \"都道府県\": prefecture,\n",
    "                \"人口密度\": population_density\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"データ取得エラー: {e}\")\n",
    "\n",
    "# WebDriverを終了\n",
    "driver.quit()\n",
    "\n",
    "# 最後の48個のデータだけ表示\n",
    "for data in population_density_data[-47:]:\n",
    "    print(data)\n",
    "\n",
    "# 必要に応じてCSVに保存\n",
    "df = pd.DataFrame(population_density_data)\n",
    "df.to_csv(\"population_density.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# SQLiteデータベースに接続（なければ作成されます）\n",
    "conn = sqlite3.connect('population_density.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "# データベースにテーブルを作成\n",
    "c.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS population_density (\n",
    "        順位 INTEGER PRIMARY KEY,\n",
    "        都道府県 TEXT,\n",
    "        人口密度 TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# データベースにデータを挿入\n",
    "for index, row in df.iterrows():\n",
    "    c.execute('''\n",
    "        INSERT OR REPLACE INTO population_density (順位, 都道府県, 人口密度) VALUES (?, ?, ?)\n",
    "    ''', (row['順位'], row['都道府県'], row['人口密度']))\n",
    "\n",
    "# データベースへの保存確認\n",
    "conn.commit()\n",
    "\n",
    "# データベース接続を閉じる\n",
    "conn.close()\n",
    "\n",
    "print(\"データベースに保存完了\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# データの読み込み\n",
    "onsen_df = pd.read_csv(\"onsen_ranking_fixed.csv\", encoding=\"utf-8-sig\")\n",
    "population_density_df = pd.read_csv(\"population_density.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "# 都道府県でマージ\n",
    "merged_df = pd.merge(onsen_df[['順位', 'エリア名']], population_density_df[['順位', '都道府県']], left_on='エリア名', right_on='都道府県')\n",
    "\n",
    "# 温泉の順位と人口密度の順位をそれぞれ取り出す\n",
    "onsen_ranking = merged_df['順位_x']\n",
    "population_density_ranking = merged_df['順位_y']\n",
    "\n",
    "# 相関計算\n",
    "correlation = onsen_ranking.corr(population_density_ranking)\n",
    "\n",
    "# 結果を表示\n",
    "print(f\"温泉ランキングと人口密度ランキングの相関係数: {correlation}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
